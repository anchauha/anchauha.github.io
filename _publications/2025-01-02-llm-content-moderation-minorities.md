---
title: "Can LLM-based Content Moderation Identify Insensitive Speech toward Indigenous Ethnic and Religious Minorities?"
collection: publications
permalink: /publication/2025-01-02-llm-content-moderation-minorities
# excerpt: 'This paper investigates the epistemic limits of LLM-based moderation systems and explores methods for incorporating minority perspectives using RAG-enhanced moderation.'
date: 2025-01-02
# venue: 'ACM Journal on Computing and Sustainable Societies (Under review)'
paperurl: 'https://www.diptodas.net/files/papers/Mod_Guide.pdf'
citation: 'Dipto Das, Achhiya Sultana, <b>Ankit Singh Chauhan</b>, Saadia Binte Alam, Mohammad Shidujaman, Sunandan Chakraborty, and Syed Ishtiaque Ahmed.  (2025). &quot;Can LLM-based Content Moderation Identify Insensitive Speech toward Indigenous Ethnic and Religious Minorities?&quot; <i>ACM Journal on Computing and Sustainable Societies</i>.  (Under review)'
---

Language operates as a mechanism of both marginalization and resistance, especially for minority communities navigating insensitive and harmful speech online. As content moderation increasingly depends on large language models (LLMs), concerns arise about whether these systems can recognize culturally insensitive speech from the perspectives of historically underrepresented groups. Focusing on Bangladesh's Hindu and Chakma communities–the country's largest religious and Indigenous ethnic minorities, respectively–this paper investigates the epistemic limits of LLM-based moderation systems and explores methods for incorporating minority perspectives.  We co-created a culturally grounded corpus of insensitive speech with community members and integrated their narratives into moderation pipelines using retrieval-augmented generation (RAG). Our tool, Mod-Guide, improves LLM sensitivity to minority viewpoints by leveraging contextual cues derived from lived experience. Through mixed-method evaluations involving both minority and majority participants, we demonstrate that RAG-enhanced moderation responses are more contextually accurate and perceived differently across ethnic lines. This work advances research in human-computer interaction, AI ethics, and social computing by foregrounding restorative justice and hermeneutical inclusion in the design of content moderation systems.

<!-- [Download paper here](https://www.diptodas.net/files/papers/Mod_Guide.pdf) -->
<!-- [Code repository](http://github.com/example/repo) -->
